{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CIFAR-10\n\nThe CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10 classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets contains 10,000 images.\n\nI choose Keras as my deep learning framework since it is begginer friendly and it is what we mainly use in our textbook.\n\nThe challenge is to recognize previously unseen images and assign them to one of the 10 classes.","metadata":{}},{"cell_type":"markdown","source":"### Import Data\n\nWe are going to import data directly from the Keras datasets. First, divide the dataset into train data, validation data and test data.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import cifar10\nimport seaborn as sns\n\n(X_train_full, y_train_full), (X_test, y_test)=cifar10.load_data()\nX_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\ny_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n\nprint('Shape of X_train is {}'.format(X_train.shape))\nprint('Shape of X_valid is {}'.format(X_valid.shape))\nprint('Shape of X_test is {}'.format(X_test.shape))\nprint('Shape of y_train is {}'.format(y_train.shape))\nprint('Shape of y_valid is {}'.format(y_valid.shape))\nprint('Shape of y_test is {}'.format(y_test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:11:25.156348Z","iopub.execute_input":"2021-12-18T16:11:25.156863Z","iopub.status.idle":"2021-12-18T16:11:26.533727Z","shell.execute_reply.started":"2021-12-18T16:11:25.156813Z","shell.execute_reply":"2021-12-18T16:11:26.533034Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Shape of X_train is (45000, 32, 32, 3)\nShape of X_valid is (5000, 32, 32, 3)\nShape of X_test is (10000, 32, 32, 3)\nShape of y_train is (45000, 1)\nShape of y_valid is (5000, 1)\nShape of y_test is (10000, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preprocessing Data\n\nBefore we start training, it's better to preprocess the data with normalization and one hot encoding.\n\nFor normalizing the pixel data, we can simply divide the whole pixel values with 255. Since pixel values ranges from 0-255, it will bring all the values in the data into a common scale 0-1.\n\nCIFAR-10 has 10 categories, in general it's a good practice to label the categorical data using the one hot encoding. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\n# Normalization\nX_train = X_train/255\nX_valid = X_valid/255\nX_test = X_test/255\n\n# One hot encoding\ny_train = to_categorical(y_train,10)\ny_valid = to_categorical(y_valid,10)\ny_test = to_categorical(y_test,10)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T16:23:14.027970Z","iopub.execute_input":"2021-12-18T16:23:14.028670Z","iopub.status.idle":"2021-12-18T16:23:14.499487Z","shell.execute_reply.started":"2021-12-18T16:23:14.028628Z","shell.execute_reply":"2021-12-18T16:23:14.495225Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Basic CNN Model\n\nThe first model I choose is a basic convolution neural network. CNN is proven very effective on image data. \n\nWe will start with 3 convolutonal layers with the input shape of (32,32,3) and the activation function 'relu'. The first layer will have 32 filters, and the number of filters doubles as we climb up the CNN towards the output layer (32->64->128). A batch normalization is used in each layer to keep the input zero-centered and scaled. Each layer is attached to a maxpool layer. Max pooling is a great way to reduce the size of parameters with out loosing much information.\n\nIn order to avoid overfitting, we'll apply some regularization techniques as well. Here I choose to drop out some of the neural units randomly from our network. This forces the next layer to learn the patterns again, which will make our model more robust. The initial dropout rate is 0.2, and we'll increase the rate by 0.1 for each layer towards the output layer.\n\nAfter 3 convolutional layers, we will flatten the intermediate results and pass them to a Dense network. Then the dense network result will be passed to a final output layer, where the number of units represent the number of categories in the data, which is 10 in our case. Softmax is chosen as final activation because we need the highest probable class out of 10. Finally we'll compile the model using adam optimizer.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n\nmodel1 = Sequential()\nmodel1.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPooling2D((2, 2)))\nmodel1.add(Dropout(0.2))\nmodel1.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPooling2D((2, 2)))\nmodel1.add(Dropout(0.3))\nmodel1.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPooling2D((2, 2)))\nmodel1.add(Dropout(0.4))\nmodel1.add(Flatten())\nmodel1.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.5))\nmodel1.add(Dense(10, activation='softmax'))\n\n# compile model\n# opt = SGD(lr=0.001, momentum=0.9)\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# model5.fit_generator(train_generator,epochs=200,steps_per_epoch=training_steps,validation_data=test_generator,validation_steps=validation_steps,callbacks=[board])\nhistory1 = model1.fit(X_train, y_train, epochs=50,validation_data=(X_valid,y_valid))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T17:07:11.253781Z","iopub.execute_input":"2021-12-18T17:07:11.254147Z","iopub.status.idle":"2021-12-18T17:14:41.606085Z","shell.execute_reply.started":"2021-12-18T17:07:11.254112Z","shell.execute_reply":"2021-12-18T17:14:41.605363Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2021-12-18 17:07:12.804901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2021-12-18 17:07:14.530697: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1407/1407 [==============================] - 17s 7ms/step - loss: 1.6000 - accuracy: 0.4449 - val_loss: 1.1701 - val_accuracy: 0.5902\nEpoch 2/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 1.0936 - accuracy: 0.6120 - val_loss: 0.9734 - val_accuracy: 0.6524\nEpoch 3/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.9222 - accuracy: 0.6776 - val_loss: 0.7232 - val_accuracy: 0.7486\nEpoch 4/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.8223 - accuracy: 0.7164 - val_loss: 0.7367 - val_accuracy: 0.7416\nEpoch 5/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.7422 - accuracy: 0.7431 - val_loss: 0.6956 - val_accuracy: 0.7626\nEpoch 6/50\n1407/1407 [==============================] - 8s 6ms/step - loss: 0.6788 - accuracy: 0.7660 - val_loss: 0.5743 - val_accuracy: 0.8066\nEpoch 7/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.6321 - accuracy: 0.7847 - val_loss: 0.5763 - val_accuracy: 0.8054\nEpoch 8/50\n1407/1407 [==============================] - 9s 7ms/step - loss: 0.5986 - accuracy: 0.7941 - val_loss: 0.5547 - val_accuracy: 0.8144\nEpoch 9/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.5583 - accuracy: 0.8099 - val_loss: 0.5146 - val_accuracy: 0.8294\nEpoch 10/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.5283 - accuracy: 0.8199 - val_loss: 0.5250 - val_accuracy: 0.8254\nEpoch 11/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.5097 - accuracy: 0.8256 - val_loss: 0.4804 - val_accuracy: 0.8326\nEpoch 12/50\n1407/1407 [==============================] - 9s 7ms/step - loss: 0.4872 - accuracy: 0.8345 - val_loss: 0.5081 - val_accuracy: 0.8322\nEpoch 13/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.4614 - accuracy: 0.8418 - val_loss: 0.4845 - val_accuracy: 0.8386\nEpoch 14/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.4483 - accuracy: 0.8489 - val_loss: 0.4586 - val_accuracy: 0.8420\nEpoch 15/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.4293 - accuracy: 0.8512 - val_loss: 0.4394 - val_accuracy: 0.8582\nEpoch 16/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.4158 - accuracy: 0.8577 - val_loss: 0.4532 - val_accuracy: 0.8554\nEpoch 17/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.4025 - accuracy: 0.8626 - val_loss: 0.4308 - val_accuracy: 0.8566\nEpoch 18/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3886 - accuracy: 0.8654 - val_loss: 0.4436 - val_accuracy: 0.8504\nEpoch 19/50\n1407/1407 [==============================] - 9s 7ms/step - loss: 0.3788 - accuracy: 0.8694 - val_loss: 0.4600 - val_accuracy: 0.8536\nEpoch 20/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3615 - accuracy: 0.8750 - val_loss: 0.4730 - val_accuracy: 0.8456\nEpoch 21/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3568 - accuracy: 0.8765 - val_loss: 0.4628 - val_accuracy: 0.8522\nEpoch 22/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3476 - accuracy: 0.8798 - val_loss: 0.4322 - val_accuracy: 0.8628\nEpoch 23/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3404 - accuracy: 0.8824 - val_loss: 0.4813 - val_accuracy: 0.8564\nEpoch 24/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3298 - accuracy: 0.8863 - val_loss: 0.4653 - val_accuracy: 0.8542\nEpoch 25/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3254 - accuracy: 0.8894 - val_loss: 0.4205 - val_accuracy: 0.8706\nEpoch 26/50\n1407/1407 [==============================] - 8s 6ms/step - loss: 0.3222 - accuracy: 0.8894 - val_loss: 0.4391 - val_accuracy: 0.8582\nEpoch 27/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3078 - accuracy: 0.8932 - val_loss: 0.4205 - val_accuracy: 0.8692\nEpoch 28/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.3095 - accuracy: 0.8914 - val_loss: 0.4261 - val_accuracy: 0.8692\nEpoch 29/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2927 - accuracy: 0.8987 - val_loss: 0.4314 - val_accuracy: 0.8670\nEpoch 30/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2944 - accuracy: 0.8974 - val_loss: 0.4214 - val_accuracy: 0.8698\nEpoch 31/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2903 - accuracy: 0.8995 - val_loss: 0.4503 - val_accuracy: 0.8638\nEpoch 32/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2783 - accuracy: 0.9053 - val_loss: 0.4776 - val_accuracy: 0.8580\nEpoch 33/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2749 - accuracy: 0.9052 - val_loss: 0.4161 - val_accuracy: 0.8688\nEpoch 34/50\n1407/1407 [==============================] - 9s 7ms/step - loss: 0.2729 - accuracy: 0.9050 - val_loss: 0.4394 - val_accuracy: 0.8588\nEpoch 35/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2605 - accuracy: 0.9097 - val_loss: 0.4733 - val_accuracy: 0.8624\nEpoch 36/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2692 - accuracy: 0.9075 - val_loss: 0.4550 - val_accuracy: 0.8610\nEpoch 37/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2593 - accuracy: 0.9100 - val_loss: 0.4074 - val_accuracy: 0.8762\nEpoch 38/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2591 - accuracy: 0.9094 - val_loss: 0.4424 - val_accuracy: 0.8712\nEpoch 39/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2514 - accuracy: 0.9130 - val_loss: 0.4347 - val_accuracy: 0.8678\nEpoch 40/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2434 - accuracy: 0.9146 - val_loss: 0.4302 - val_accuracy: 0.8692\nEpoch 41/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2459 - accuracy: 0.9146 - val_loss: 0.4248 - val_accuracy: 0.8748\nEpoch 42/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2463 - accuracy: 0.9148 - val_loss: 0.4479 - val_accuracy: 0.8680\nEpoch 43/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2310 - accuracy: 0.9207 - val_loss: 0.4599 - val_accuracy: 0.8666\nEpoch 44/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2381 - accuracy: 0.9190 - val_loss: 0.4994 - val_accuracy: 0.8558\nEpoch 45/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2276 - accuracy: 0.9206 - val_loss: 0.4274 - val_accuracy: 0.8784\nEpoch 46/50\n1407/1407 [==============================] - 9s 7ms/step - loss: 0.2313 - accuracy: 0.9201 - val_loss: 0.4134 - val_accuracy: 0.8776\nEpoch 47/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2297 - accuracy: 0.9194 - val_loss: 0.4477 - val_accuracy: 0.8704\nEpoch 48/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2202 - accuracy: 0.9233 - val_loss: 0.4515 - val_accuracy: 0.8718\nEpoch 49/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2204 - accuracy: 0.9241 - val_loss: 0.4280 - val_accuracy: 0.8744\nEpoch 50/50\n1407/1407 [==============================] - 9s 6ms/step - loss: 0.2188 - accuracy: 0.9239 - val_loss: 0.4581 - val_accuracy: 0.8672\n","output_type":"stream"}]}]}